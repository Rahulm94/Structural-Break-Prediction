{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import ttest_ind, ks_2samp, levene\n",
    "from scipy.stats import entropy, normaltest, jarque_bera\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.signal import periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(\"data/X_train.parquet\")\n",
    "y_train = pd.read_parquet(\"data/y_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.read_parquet(\"data/X_test.reduced.parquet\")\n",
    "# y_test = pd.read_parquet(\"data/y_test.reduced.parquet\")\n",
    "\n",
    "# df = X_test.loc[10001:10001]\n",
    "# df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features_list = []\n",
    "# for n in tqdm.tqdm(windows):\n",
    "#     mask_pre  = (pos >= -n) & (pos <= -1)\n",
    "#     mask_post = (pos >= 0)  & (pos <=  n-1)\n",
    "\n",
    "#     pre = (df[mask_pre]\n",
    "#            .groupby('id')['value']\n",
    "#            .agg(agg_funcs)\n",
    "#            .sort_index())\n",
    "#     pre.columns = [f'value_{c}_pre_{n}' for c in pre.columns]\n",
    "\n",
    "#     post = (df[mask_post]\n",
    "#             .groupby('id')['value']\n",
    "#             .agg(agg_funcs)\n",
    "#             .sort_index())\n",
    "#     post.columns = [f'value_{c}_post_{n}' for c in post.columns]\n",
    "\n",
    "#     # vectorized slopes\n",
    "#     pre[f'value_slope_pre_{n}']  = (pre[f'value_last_pre_{n}']  - pre[f'value_first_pre_{n}'])  / pre[f'value_count_pre_{n}']\n",
    "#     post[f'value_slope_post_{n}'] = (post[f'value_last_post_{n}'] - post[f'value_first_post_{n}']) / post[f'value_count_post_{n}']\n",
    "\n",
    "#     df_features_list.extend([pre, post])\n",
    "\n",
    "# df_features = pd.concat(df_features_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ruptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ruptures\n",
    "import ruptures as rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[10001:10010]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of data\n",
    "# n = 500  # number of samples\n",
    "# n_bkps, sigma = 3, 5  # number of change points, noise standard deviation\n",
    "# signal, bkps = rpt.pw_constant(n, dim, n_bkps, noise_std=sigma)\n",
    "\n",
    "# change point detection\n",
    "model = \"rbf\"  # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\",...\n",
    "signal = df[['value']]\n",
    "\n",
    "# Dynamic Programming\n",
    "# algo = rpt.Dynp(model=model, min_size=3, jump=5).fit(signal)\n",
    "# bkps = algo.predict(n_bkps=1)\n",
    "\n",
    "# Linearly penalized segmentation\n",
    "# algo = rpt.Pelt(model=model, min_size=3, jump=5).fit(signal)\n",
    "# bkps = algo.predict(pen=2)\n",
    "\n",
    "# Binary Segmentation Model\n",
    "algo = rpt.Binseg(model=model).fit(signal)\n",
    "bkps = algo.predict(n_bkps=1)\n",
    "\n",
    "# Bottom-Up Model\n",
    "# algo = rpt.BottomUp(model=model).fit(signal)\n",
    "# bkps = algo.predict(n_bkps=1)\n",
    "\n",
    "# Window-based change point detection\n",
    "# algo = rpt.Window(width=40, model=model).fit(signal)\n",
    "# bkps = algo.predict(n_bkps=1)\n",
    "\n",
    "print(bkps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "rpt.show.display(signal, bkps, figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting changefinder==0.1\n",
      "  Downloading changefinder-0.1.tar.gz (3.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (d:\\softwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (d:\\softwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\softwares\\anaconda\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1 lines of output]\n",
      "  ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install changefinder==0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Fourier Transforms (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "\n",
    "def extract_main_frequencies(time_series_data, sampling_rate=1, num_main_freqs=3):\n",
    "    \"\"\"\n",
    "    Extracts the main frequencies from time series data using a periodogram.\n",
    "\n",
    "    Args:\n",
    "        time_series_data (np.array): The input time series data.\n",
    "        sampling_rate (float): The sampling rate of the time series data (samples per unit time).\n",
    "        num_main_freqs (int): The number of main frequencies to extract.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the top frequencies, their corresponding periods,\n",
    "              and their power spectral densities.\n",
    "    \"\"\"\n",
    "    # Estimate power spectral density using a periodogram\n",
    "    frequencies, power_spectral_density = periodogram(time_series_data, fs=sampling_rate)\n",
    "\n",
    "    # Get indices for the highest power spectral density values\n",
    "    top_freq_indices = np.argsort(power_spectral_density)[::-1][:num_main_freqs]\n",
    "\n",
    "    # Extract the top frequencies, powers, and calculate periods\n",
    "    main_frequencies = frequencies[top_freq_indices]\n",
    "    main_powers = power_spectral_density[top_freq_indices]\n",
    "    main_periods = 1 / main_frequencies\n",
    "\n",
    "    results = {}\n",
    "    for i in range(num_main_freqs):\n",
    "        results[f'freq_{i+1}'] = main_frequencies[i]\n",
    "        results[f'period_{i+1}'] = main_periods[i]\n",
    "        results[f'power_{i+1}'] = main_powers[i]\n",
    "    \n",
    "    df_freq = pd.DataFrame(results, index=[0])\n",
    "    return df_freq\n",
    "\n",
    "df_features = pd.DataFrame()\n",
    "# Generate frequency features for pre and post boundary signals\n",
    "for period in (0, 1):\n",
    "    suffix = '_pre' if period == 0 else '_post'\n",
    "    freq_features = df[df['period'] == period].groupby('id').apply(lambda x: extract_main_frequencies(x['value']))\n",
    "    freq_features = freq_features.droplevel(1).filter(regex='^freq|^power')\n",
    "    freq_features.columns = [col + suffix for col in freq_features.columns]\n",
    "\n",
    "    df_features = pd.concat([df_features, freq_features], axis=1)\n",
    "\n",
    "for n in range(1, 4):\n",
    "    df_features[f'diff_freq_{n}'] = df_features[f'freq_{n}_post'] - df_features[f'freq_{n}_pre']\n",
    "    df_features[f'avg_freq_{n}'] =  (df_features[f'freq_{n}_post'] + df_features[f'freq_{n}_pre'])/2\n",
    "    df_features[f'pct_change_freq_{n}'] = df_features.apply(lambda x: round(x[f'diff_freq_{n}']/x[f'avg_freq_{n}'], 4)\n",
    "                                                             if x[f'avg_freq_{n}'] != 0 else np.nan, axis=1)\n",
    "feature_cols = df_features.filter(regex='^pct_change.*').columns\n",
    "df_features[feature_cols]\n",
    "\n",
    "# main_freq_info, freqs, psd = extract_main_frequencies(signal_0, sampling_rate=1, num_main_freqs=3)\n",
    "# print(\"Main Frequencies Information:\")\n",
    "# for key, value in main_freq_info.items():\n",
    "#     print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "# main_freq_info, freqs, psd = extract_main_frequencies(signal_1, sampling_rate=1, num_main_freqs=3)\n",
    "# print(\"Main Frequencies Information:\")\n",
    "# for key, value in main_freq_info.items():\n",
    "#     print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "\n",
    "# Plotting the Periodogram (optional)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(freqs, psd)\n",
    "# plt.title('Periodogram of Time Series Data')\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Power Spectral Density')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_funcs = [('mean', 'mean'), ('std', 'std'), ('max', 'max'), ('min', 'min'), ('median', 'median'), ('skew', 'skew'), ('kurtosis', lambda y: y.kurt()), ('count', 'count'), ('first', 'first'), ('last', 'last'),\n",
    "             ('trend', lambda y: np.mean(np.diff(y))), ('volatility', lambda y: np.std(np.diff(y))), ('range', lambda y: np.max(y) - np.min(y)),\n",
    "             ('mean_absolute_change', lambda y: np.mean(np.abs(np.diff(y)))), ('max_jump', lambda y: np.max(np.abs(np.diff(y)))), # Change dynamics\n",
    "             ('num_turning_points', lambda y: np.sum(np.diff(np.sign(np.diff(y))) != 0)), ('upward_steps', lambda y:  np.sum(np.diff(y) > 0)), ('downward_steps', lambda y: np.sum(np.diff(y) < 0)), # Complexity\n",
    "             ('entropy', lambda y: lambda y: entropy(np.histogram(y, bins=20, density=True)[0])),  ('normality', lambda y: normaltest(y)[0]), # Distribution shape\n",
    "             ('auto_1', lambda y: y.autocorr(lag=1)), ('auto_2', lambda y: y.autocorr(lag=2)), ('auto_3', lambda y: y.autocorr(lag=3)), ('stationarity', lambda y: adfuller(y)[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
